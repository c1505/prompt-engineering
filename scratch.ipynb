{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message(message):\n",
    "    result = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        ]\n",
    "    )\n",
    "    return result.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the meaning of life?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_2 = \"Explain to me what a transformer model is in simple terms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = f\"\"\"\n",
    "{question_2} Let's work this out in a step by step way to be sure we have the right answer\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, a transformer model is a type of artificial neural network used for natural language processing tasks such as language translation, sentiment analysis, and summarization. Here's a more detailed step-by-step explanation:\n",
      "\n",
      "1. At its core, the transformer model is based on the concept of Attention, which allows the model to focus on different parts of the input sequence at different times.\n",
      "\n",
      "2. A transformer model consists of a series of layers, each of which performs a specific operation on the input sequence. The layers are typically composed of two types of sub-layers: Encoder layers and Decoder layers.\n",
      "\n",
      "3. The Encoder layers are responsible for processing the input text sequence and creating a representation of it, which is then passed on to the Decoder layers.\n",
      "\n",
      "4. The Decoder layers use the information from the Encoder layers to generate the output sequence. Attention is used to ensure that the decoder focuses on the most relevant parts of the input sequence as it generates the output.\n",
      "\n",
      "5. The Transformer model has become very popular in recent years due to its ability to generate high-quality outputs without the need for recurrent connections, which can be computationally expensive.\n",
      "\n",
      "In summary, a transformer model is a neural network architecture that uses Attention and a series of layers to process input text sequences and generate output sequences for natural language processing tasks.\n"
     ]
    }
   ],
   "source": [
    "response_1 = send_message(prompt_1)\n",
    "print(response_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, I'd be happy to help you understand what a transformer model is. Here's a step-by-step explanation:\n",
      "\n",
      "1. A transformer model is a type of deep learning model that is used for natural language processing (NLP) tasks, such as language translation or text generation.\n",
      "\n",
      "2. It uses a technique called self-attention, which allows the model to focus on different parts of the input sequence when making predictions.\n",
      "\n",
      "3. This is different from traditional sequence-to-sequence models, which process the input sequence one step at a time and can struggle with long-term dependencies.\n",
      "\n",
      "4. The transformer model was first introduced in a 2017 paper by researchers at Google, and has since become a popular architecture for NLP tasks.\n",
      "\n",
      "5. Some well-known examples of transformer-based models include BERT, GPT-2, and T5.\n",
      "\n",
      "6. In summary, a transformer model is a powerful tool for processing natural language data, and uses self-attention to efficiently learn long-term dependencies in the input sequence.\n"
     ]
    }
   ],
   "source": [
    "response_2 = send_message(prompt_1)\n",
    "print(response_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, I'd be happy to help you understand what a transformer model is! Here are the steps to explain it in simple terms:\n",
      "\n",
      "Step 1: Transformers are a type of neural network architecture used in natural language processing (NLP) to process and understand large amounts of text.\n",
      "\n",
      "Step 2: The transformer model was first introduced in 2017 by Google and was designed to address some of the limitations of traditional RNN-based models that were used for NLP tasks.\n",
      "\n",
      "Step 3: The transformer model uses a technique called attention, which allows it to selectively focus on certain parts of the input sequence while processing it.\n",
      "\n",
      "Step 4: This attention mechanism helps the transformer model to better understand the meaning and context of words in a sentence, which is important for tasks like language translation and sentiment analysis.\n",
      "\n",
      "Step 5: Unlike traditional RNNs, which process input sequences sequentially, the transformer model processes input sequences in parallel, which makes it faster and more efficient.\n",
      "\n",
      "Step 6: Overall, the transformer model has become a popular and powerful tool for NLP tasks, and it has been used in a wide range of applications, from chatbots and language translation to speech recognition and text-based question answering systems.\n"
     ]
    }
   ],
   "source": [
    "response_3 = send_message(prompt_1)\n",
    "print(response_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the first request 3 times with a relatively high temperature\n",
    "# store the responses for each\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_prompt = f\"\"\"\n",
    "You are a researcher tasked with investigating the 3 response options provided.  \n",
    "List the flaws and faulty logic of each answer option. Let's work this out in a \n",
    "step by step way to be sure we have all the errors.\n",
    "\"\"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_plus_responses = researcher_prompt + \"response 1: \" + response_1 + \"response 2: \" + response_2 + \"response 3: \" + response_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a researcher tasked with investigating the 3 response options provided.  \n",
      "List the flaws and faulty logic of each answer option. Let's work this out in a \n",
      "step by step way to be sure we have all the errors.\n",
      "response 1: Sure, a transformer model is a type of artificial neural network used for natural language processing tasks such as language translation, sentiment analysis, and summarization. Here's a more detailed step-by-step explanation:\n",
      "\n",
      "1. At its core, the transformer model is based on the concept of Attention, which allows the model to focus on different parts of the input sequence at different times.\n",
      "\n",
      "2. A transformer model consists of a series of layers, each of which performs a specific operation on the input sequence. The layers are typically composed of two types of sub-layers: Encoder layers and Decoder layers.\n",
      "\n",
      "3. The Encoder layers are responsible for processing the input text sequence and creating a representation of it, which is then passed on to the Decoder layers.\n",
      "\n",
      "4. The Decoder layers use the information from the Encoder layers to generate the output sequence. Attention is used to ensure that the decoder focuses on the most relevant parts of the input sequence as it generates the output.\n",
      "\n",
      "5. The Transformer model has become very popular in recent years due to its ability to generate high-quality outputs without the need for recurrent connections, which can be computationally expensive.\n",
      "\n",
      "In summary, a transformer model is a neural network architecture that uses Attention and a series of layers to process input text sequences and generate output sequences for natural language processing tasks.response 2: Sure, I'd be happy to help you understand what a transformer model is. Here's a step-by-step explanation:\n",
      "\n",
      "1. A transformer model is a type of deep learning model that is used for natural language processing (NLP) tasks, such as language translation or text generation.\n",
      "\n",
      "2. It uses a technique called self-attention, which allows the model to focus on different parts of the input sequence when making predictions.\n",
      "\n",
      "3. This is different from traditional sequence-to-sequence models, which process the input sequence one step at a time and can struggle with long-term dependencies.\n",
      "\n",
      "4. The transformer model was first introduced in a 2017 paper by researchers at Google, and has since become a popular architecture for NLP tasks.\n",
      "\n",
      "5. Some well-known examples of transformer-based models include BERT, GPT-2, and T5.\n",
      "\n",
      "6. In summary, a transformer model is a powerful tool for processing natural language data, and uses self-attention to efficiently learn long-term dependencies in the input sequence.response 3: Sure, I'd be happy to help you understand what a transformer model is! Here are the steps to explain it in simple terms:\n",
      "\n",
      "Step 1: Transformers are a type of neural network architecture used in natural language processing (NLP) to process and understand large amounts of text.\n",
      "\n",
      "Step 2: The transformer model was first introduced in 2017 by Google and was designed to address some of the limitations of traditional RNN-based models that were used for NLP tasks.\n",
      "\n",
      "Step 3: The transformer model uses a technique called attention, which allows it to selectively focus on certain parts of the input sequence while processing it.\n",
      "\n",
      "Step 4: This attention mechanism helps the transformer model to better understand the meaning and context of words in a sentence, which is important for tasks like language translation and sentiment analysis.\n",
      "\n",
      "Step 5: Unlike traditional RNNs, which process input sequences sequentially, the transformer model processes input sequences in parallel, which makes it faster and more efficient.\n",
      "\n",
      "Step 6: Overall, the transformer model has become a popular and powerful tool for NLP tasks, and it has been used in a wide range of applications, from chatbots and language translation to speech recognition and text-based question answering systems.\n"
     ]
    }
   ],
   "source": [
    "print(researcher_plus_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": researcher_plus_responses}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7Eh1LfaZIJkO3hYe2tG3p1WnJ79Is at 0x7fb1f54c4fb0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"content\": \"Response 1:\\n- The flaw in this response is that it assumes that the reader is already familiar with neural networks and therefore may struggle to understand the concepts involved in the transformer model. \\n- Additionally, the explanation provided is very technical and may be difficult for someone without a background in computer science to understand.\\n\\nResponse 2:\\n- This response is more accessible and less technical than the first response, but it still assumes some prior knowledge of deep learning and NLP. \\n- The explanation of what a transformer model is mainly centers on its use of self-attention, but it may not be immediately clear what this means without further explanation.\\n\\nResponse 3:\\n- The flaw in this response is that it oversimplifies the explanation to the point where it might be incomplete or misleading. \\n- While it is important to make explanations accessible, it is also crucial to include enough detail to give the reader an accurate understanding of the topic, which this response does not fully achieve.\",\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1683736319,\n",
       "  \"id\": \"chatcmpl-7Eh1LfaZIJkO3hYe2tG3p1WnJ79Is\",\n",
       "  \"model\": \"gpt-3.5-turbo-0301\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 195,\n",
       "    \"prompt_tokens\": 783,\n",
       "    \"total_tokens\": 978\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1:\n",
      "- The flaw in this response is that it assumes that the reader is already familiar with neural networks and therefore may struggle to understand the concepts involved in the transformer model. \n",
      "- Additionally, the explanation provided is very technical and may be difficult for someone without a background in computer science to understand.\n",
      "\n",
      "Response 2:\n",
      "- This response is more accessible and less technical than the first response, but it still assumes some prior knowledge of deep learning and NLP. \n",
      "- The explanation of what a transformer model is mainly centers on its use of self-attention, but it may not be immediately clear what this means without further explanation.\n",
      "\n",
      "Response 3:\n",
      "- The flaw in this response is that it oversimplifies the explanation to the point where it might be incomplete or misleading. \n",
      "- While it is important to make explanations accessible, it is also crucial to include enough detail to give the reader an accurate understanding of the topic, which this response does not fully achieve.\n"
     ]
    }
   ],
   "source": [
    "print(result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_response = result.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolver_prompt = f\"\"\"\n",
    "You are a resolver tasked with 1) finding which of the 3 answer options the \n",
    "researcher thought was best. 2) improving that answer, and 3) Printing the improved\n",
    "answer in full.  Let's work this out in a step by step way to be sure\n",
    "we have the right answer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolver_prompt_plus_responses = resolver_prompt + \"researcher criticisms: \" + researcher_response + \"\\n orginal responses: \\n\" + \"response 1: \" + response_1 + \"response 2: \" + response_2 + \"response 3: \" + response_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "blah = \" abc \\n cdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " abc \n",
      " cdf\n"
     ]
    }
   ],
   "source": [
    "print(blah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a resolver tasked with 1) finding which of the 3 answer options the \n",
      "researcher thought was best. 2) improving that answer, and 3) Printing the improved\n",
      "answer in full.  Let's work this out in a step by step way to be sure\n",
      "we have the right answer.\n",
      "researcher criticisms: Response 1:\n",
      "- The flaw in this response is that it assumes that the reader is already familiar with neural networks and therefore may struggle to understand the concepts involved in the transformer model. \n",
      "- Additionally, the explanation provided is very technical and may be difficult for someone without a background in computer science to understand.\n",
      "\n",
      "Response 2:\n",
      "- This response is more accessible and less technical than the first response, but it still assumes some prior knowledge of deep learning and NLP. \n",
      "- The explanation of what a transformer model is mainly centers on its use of self-attention, but it may not be immediately clear what this means without further explanation.\n",
      "\n",
      "Response 3:\n",
      "- The flaw in this response is that it oversimplifies the explanation to the point where it might be incomplete or misleading. \n",
      "- While it is important to make explanations accessible, it is also crucial to include enough detail to give the reader an accurate understanding of the topic, which this response does not fully achieve.\n",
      " orginal responses: \n",
      "response 1: Sure, a transformer model is a type of artificial neural network used for natural language processing tasks such as language translation, sentiment analysis, and summarization. Here's a more detailed step-by-step explanation:\n",
      "\n",
      "1. At its core, the transformer model is based on the concept of Attention, which allows the model to focus on different parts of the input sequence at different times.\n",
      "\n",
      "2. A transformer model consists of a series of layers, each of which performs a specific operation on the input sequence. The layers are typically composed of two types of sub-layers: Encoder layers and Decoder layers.\n",
      "\n",
      "3. The Encoder layers are responsible for processing the input text sequence and creating a representation of it, which is then passed on to the Decoder layers.\n",
      "\n",
      "4. The Decoder layers use the information from the Encoder layers to generate the output sequence. Attention is used to ensure that the decoder focuses on the most relevant parts of the input sequence as it generates the output.\n",
      "\n",
      "5. The Transformer model has become very popular in recent years due to its ability to generate high-quality outputs without the need for recurrent connections, which can be computationally expensive.\n",
      "\n",
      "In summary, a transformer model is a neural network architecture that uses Attention and a series of layers to process input text sequences and generate output sequences for natural language processing tasks.response 2: Sure, I'd be happy to help you understand what a transformer model is. Here's a step-by-step explanation:\n",
      "\n",
      "1. A transformer model is a type of deep learning model that is used for natural language processing (NLP) tasks, such as language translation or text generation.\n",
      "\n",
      "2. It uses a technique called self-attention, which allows the model to focus on different parts of the input sequence when making predictions.\n",
      "\n",
      "3. This is different from traditional sequence-to-sequence models, which process the input sequence one step at a time and can struggle with long-term dependencies.\n",
      "\n",
      "4. The transformer model was first introduced in a 2017 paper by researchers at Google, and has since become a popular architecture for NLP tasks.\n",
      "\n",
      "5. Some well-known examples of transformer-based models include BERT, GPT-2, and T5.\n",
      "\n",
      "6. In summary, a transformer model is a powerful tool for processing natural language data, and uses self-attention to efficiently learn long-term dependencies in the input sequence.response 3: Sure, I'd be happy to help you understand what a transformer model is! Here are the steps to explain it in simple terms:\n",
      "\n",
      "Step 1: Transformers are a type of neural network architecture used in natural language processing (NLP) to process and understand large amounts of text.\n",
      "\n",
      "Step 2: The transformer model was first introduced in 2017 by Google and was designed to address some of the limitations of traditional RNN-based models that were used for NLP tasks.\n",
      "\n",
      "Step 3: The transformer model uses a technique called attention, which allows it to selectively focus on certain parts of the input sequence while processing it.\n",
      "\n",
      "Step 4: This attention mechanism helps the transformer model to better understand the meaning and context of words in a sentence, which is important for tasks like language translation and sentiment analysis.\n",
      "\n",
      "Step 5: Unlike traditional RNNs, which process input sequences sequentially, the transformer model processes input sequences in parallel, which makes it faster and more efficient.\n",
      "\n",
      "Step 6: Overall, the transformer model has become a popular and powerful tool for NLP tasks, and it has been used in a wide range of applications, from chatbots and language translation to speech recognition and text-based question answering systems.\n"
     ]
    }
   ],
   "source": [
    "print(resolver_prompt_plus_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": resolver_prompt_plus_responses}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the researcher's criticisms, Response 2 seems to be the best option. It is less technical than Response 1 and more concise than Response 3. However, it could benefit from some improvements to make it even clearer. Here is an improved version of Response 2:\n",
      "\n",
      "Sure, I'd be happy to explain what a transformer model is in simpler terms. Here are the key points:\n",
      "\n",
      "- A transformer model is a type of deep learning model used for natural language processing (NLP) tasks, like translating languages or generating text.\n",
      "- One of the key features of the transformer model is that it uses self-attention, which allows it to focus on different parts of the input sequence when processing it.\n",
      "- This helps the model better understand the context and meaning of the words in the input, which is important for NLP tasks.\n",
      "- Some well-known examples of transformer-based models include BERT, GPT-2, and T5.\n",
      "- Overall, the transformer model is a powerful tool for processing natural language data, and has been used in a wide range of applications.\n",
      "\n",
      "This clearer explanation of what a transformer model is should be more accessible to someone without a background in computer science or NLP.\n"
     ]
    }
   ],
   "source": [
    "print(result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure! Where would you like to go for your adventure? Do you want to explore a new city, go on a hike in nature, or perhaps take a virtual tour of a museum or historical location? Let me know what you're interested in, and I'll help plan our adventure.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "send_message(\"Take me on an adventure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "researcher-resolver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
